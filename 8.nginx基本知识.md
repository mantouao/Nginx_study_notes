# Nginx的基本知识

1. **master和worker**
   
   在启动nginx的时候会有两种很重要的进程：master 进程和 worker 进程。
   
   1. Master 进程：
      
      - Master 进程是 Nginx 的主进程，负责管理和控制其他进程。
      - 它读取和解析配置文件，并启动 Worker 进程。
      - Master 进程会监控 Worker 进程的状态，当 Worker 进程异常退出或关闭时，Master 进程会重新启动新的 Worker 进程来替代。
      - Master 进程还处理信号（如重新加载配置文件、平滑升级等），并与外部交互（如控制台命令）。
   
   2. Worker 进程：
      
      - Worker 进程是 Nginx 的工作进程，用于处理实际的客户端请求。
      - Master 进程会创建多个 Worker 进程，每个 Worker 进程都是一个独立的进程，可以并行处理请求。
      - 每个 Worker 进程都有自己的事件循环机制，可以处理客户端的连接、读写数据、处理请求等操作。
      - Worker 进程通过与 Master 进程之间的通信机制来接收配置变更、重启信号等信息。
   
   Master进程充当服务器的管理者和调度者，负责接收连接、分配任务给Worker进程，并与Client进行通信。Worker进程是服务器的工作单位，负责处理客户端的请求。Client是发起请求的一方，与服务器进行通信并接收服务器的响应。这样的架构可以通过并行处理多个连接和请求，提高服务器的性能和并发处理能力。

2. **master和worker和client交互的流程**
   
   1. 客户端发起连接请求：客户端应用程序通过网络连接到服务器，向服务器发起连接请求。
   
   2. 主进程接收连接请求：服务器的主进程（Master）负责监听指定的端口，并接收客户端的连接请求。
   
   3. 主进程分配连接给工作进程：主进程接收到客户端连接请求后，根据一定的调度策略，将连接分配给一个工作进程（Worker）来处理。
   
   4. 工作进程处理请求：工作进程接收到连接后，与客户端建立连接，并开始处理客户端的请求。工作进程负责处理请求的解析、业务逻辑处理、数据库访问等操作。
   
   5. 工作进程与客户端通信：工作进程与客户端建立的连接用于双向通信，工作进程接收客户端发送的请求数据，处理请求后生成响应数据，并将响应发送回客户端。

3. **worker的工作过程**
   
   在某些服务器架构中，工作进程（Worker）可以使用争抢的方式来获取主进程（Master）分配的任务。这种方式通常被称为**任务抢占**（Task Preemption）或任务竞争（Task Racing）。
   
   在任务抢占的情况下，工作进程会主动向主进程发出请求，表明自己可以接受任务。主进程会将任务分配给第一个成功抢占的工作进程，其他工作进程则不会获得该任务。
   
   以下是一个简单的示例过程：
   
   1. 主进程接收连接请求：主进程监听端口，接收客户端的连接请求。
   
   2. 工作进程准备就绪：工作进程在启动时，通过进程间通信机制与主进程建立联系，并准备接收任务。
   
   3. 主进程收到连接请求后，将请求任务放入任务队列。
   
   4. 工作进程抢占任务：工作进程向主进程发送请求，表明自己可以接受任务。
   
   5. 主进程选择工作进程：主进程从所有发出请求的工作进程中选择一个，将任务分配给它。
   
   6. 被选中的工作进程处理任务：被选中的工作进程接收到任务后，进行处理。
   
   7. 其他工作进程继续等待：其他工作进程未被选中，继续等待下一个任务的抢占机会。
   
   任务抢占的方式可以使得任务被快速分配给可用的工作进程，并提高任务的处理效率。然而，任务抢占也可能导致不公平的任务分配或资源不均衡的问题。因此，在设计服务器架构时，需要考虑任务抢占的合理性和公平性，以确保整体性能和负载均衡。

4. **一个master与多个worker**
   
   优点：
   
   1. 并发处理能力：多个工作进程可以并行处理多个连接和请求，提高服务器的并发处理能力。每个工作进程都可以独立地处理请求，从而提高服务器的吞吐量。
   
   2. 负载均衡：主进程负责监听和接收连接请求，并将请求分配给空闲的工作进程。通过合理的调度策略，可以实现负载均衡，将请求均匀地分配给不同的工作进程，提高系统的整体性能和稳定性。
   
   3. 故障隔离：由于每个工作进程是独立的实例，它们之间相互隔离。如果某个工作进程出现问题（例如崩溃或异常），其他工作进程可以继续处理请求，系统的可靠性和稳定性更高。
   
   4. 可扩展性：通过增加工作进程的数量，可以水平扩展服务器的处理能力，以适应不断增长的负载和用户数量。这种扩展方式相对简单，并且可以根据需求进行灵活调整。
   
   劣势：
   
   1. 进程间通信开销：主进程和工作进程之间需要进行进程间通信（IPC），这会引入一定的开销。例如，工作进程抢占任务时，需要与主进程进行通信，这会增加延迟和系统开销。
   
   2. 共享资源管理：多个工作进程可能需要共享某些资源，例如数据库连接池或缓存。在设计和管理共享资源时需要小心，以避免竞争条件和数据一致性等问题。
   
   3. 系统复杂性：引入多个工作进程会增加系统的复杂性。需要考虑进程间通信、任务调度、错误处理和监控等方面的问题。这对于开发和维护团队来说可能需要更多的工作和技术知识。
   
   4. 内存消耗：每个工作进程都需要一定的内存空间来维护自己的状态和处理请求。如果工作进程数量过多或者每个工作进程的内存占用较大，可能会增加服务器的内存消耗。
   
   一般worker的数量与cpu的数量相等为好

5. **连接数 worker_connection**
   
   1. 发送请求占用了几个worker_connection的连接数
      
      答：2个或4个，建立一个连接的时候会占用请求和响应的两个连接数，在访问静态资源的时候通常在nginx上访问，所以只用2个，在访问数据库或其他动态资源的时候nginx会代理到tomcat又会占用2个连接数，所以是4个
   
   2. worker的最大并发数量怎么算
      
      静态资源：（worker的数量×每个worker的最大连接数量）/ 2
      
      动态资源：（worker的数量×每个worker的最大连接数量）/ 4




